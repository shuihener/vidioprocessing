{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0xaedfc810>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "Mode = VideoMode(640,480,24)\n",
    "hdmi_out = base.video.hdmi_out\n",
    "hdmi_out.configure(Mode,PIXEL_BGR)\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "face_cascade1 = cv2.CascadeClassifier(\n",
    "    '/home/xilinx/jupyter_notebooks/base/video/data/'\n",
    "    'haarcascade_frontalface_default.xml')\n",
    "flag=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [\"\", \"TSP\", \"WMQ\",\"YJD\"]\n",
    "\n",
    "def detect_face(img):\n",
    "    #convert the test image to gray image as opencv face detector expects gray images\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #load OpenCV face detector, I am using LBP which is fast\n",
    "    #there is also a more accurate but slow Haar classifier\n",
    "    face_cascade = cv2.CascadeClassifier('lbpcascade_frontalface.xml')\n",
    "\n",
    "    #let's detect multiscale (some images may be closer to camera than others) images\n",
    "    #result is a list of faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5);\n",
    "    \n",
    "    #if no faces are detected then return original img\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    \n",
    "    #under the assumption that there will be only one face,\n",
    "    #extract the face area\n",
    "    (x, y, w, h) = faces[0]\n",
    "    \n",
    "    #return only the face part of the image\n",
    "    return gray[y:y+w, x:x+h], faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_folder_path):\n",
    "    \n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    \n",
    "\n",
    "    faces = []\n",
    "   \n",
    "    labels = []\n",
    "    \n",
    "    for dir_name in dirs:\n",
    "\n",
    "        if not dir_name.startswith(\"s\"):\n",
    "            continue;\n",
    "            \n",
    "        \n",
    "        label = int(dir_name.replace(\"s\", \"\"))\n",
    "        \n",
    "\n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    "       \n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        \n",
    "     \n",
    "        for image_name in subject_images_names:\n",
    "           \n",
    "            if image_name.startswith(\".\"):\n",
    "                continue;\n",
    "            \n",
    "            image_path = subject_dir_path + \"/\" + image_name\n",
    "\n",
    "           \n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            \n",
    "            #detect face\n",
    "            face, rect = detect_face(image)\n",
    "            \n",
    "            #------STEP-4--------\n",
    "            #for the purpose of this tutorial\n",
    "            #we will ignore faces that are not detected\n",
    "            if face is not None:\n",
    "                #add face to list of faces\n",
    "                faces.append(face)\n",
    "                #add label for this face\n",
    "                labels.append(label)\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return faces, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces, labels = prepare_training_data(\"training-data\")\n",
    "face_recognizer = cv2.face.createLBPHFaceRecognizer()\n",
    "face_recognizer.train(faces, np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(img, rect):\n",
    "    (x, y, w, h) = rect\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text(img, text, x, y):\n",
    "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_img):\n",
    "    #make a copy of the image as we don't want to chang original image\n",
    "    img = test_img.copy()\n",
    "    #detect face from the image\n",
    "    face, rect = detect_face(img)\n",
    "    \n",
    "    # print (face)\n",
    "    \n",
    "    if(face is None):\n",
    "        return img\n",
    "    #predict the image using our face recognizer\n",
    "    else:\n",
    "        label= face_recognizer.predict(face)\n",
    "    #get name of respective label returned by face recognizer\n",
    "        label_text = subjects[label]\n",
    "    \n",
    "    #draw a rectangle around face detected\n",
    "        draw_rectangle(img, rect)\n",
    "    #draw name of predicted person\n",
    "        draw_text(img, label_text, rect[0], rect[1]-5)\n",
    "    \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "#获取第一帧\n",
    "size1 = (160,120)\n",
    "fx=4\n",
    "fy=4\n",
    "\n",
    "    \n",
    "\n",
    "while(1):     \n",
    "    if(base.switches[0].read() == 1 and base.switches[1].read() == 0):\n",
    "        \n",
    "        if(flag==0):\n",
    "            ret, frame1 = cap.read()\n",
    "            if(ret):\n",
    "                frame1 = cv2.resize(frame1,size1,interpolation=cv2.INTER_AREA)\n",
    "                prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "                hsv = np.zeros_like(frame1)\n",
    "    #遍历每一行的第1列\n",
    "                hsv[...,1] = 255\n",
    "                flag=1\n",
    "            else:\n",
    "                raise RuntimeError(\"Failed to read from camera.\")\n",
    "        \n",
    "        ret, frame2 = cap.read()\n",
    "        if(ret):\n",
    "            frame2 = cv2.resize(frame2,size1,interpolation=cv2.INTER_AREA)\n",
    "            next1 = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #返回一个两通道的光流向量，实际上是每个点的像素位移值\n",
    "            flow = cv2.calcOpticalFlowFarneback(prvs,next1, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    #print(flow.shape)\n",
    "    #print(flow)\n",
    "\n",
    "    #笛卡尔坐标转换为极坐标，获得极轴和极角\n",
    "            mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "            hsv[...,0] = ang*180/np.pi/2\n",
    "            hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "            rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "            rgb = cv2.resize(rgb, (0, 0), fx=fx, fy=fy, interpolation=cv2.INTER_CUBIC)\n",
    "            outframe = hdmi_out.newframe()\n",
    "            outframe[0:480,0:640,:] = rgb[0:480,0:640,:]\n",
    "            hdmi_out.writeframe(outframe)\n",
    "\n",
    "    #cv2.imshow('frame2',rgb)\n",
    "    #k = cv2.waitKey(30) & 0xff\n",
    "    #if k == 27:\n",
    "    #    break\n",
    "    #elif k == ord('s'):\n",
    "    #    cv2.imwrite('opticalfb.png',frame2)\n",
    "    #   cv2.imwrite('opticalhsv.png',rgb)\n",
    "            prvs = next1\n",
    "        else:\n",
    "            raise RuntimeError(\"Failed to read from camera.\")\n",
    "            \n",
    "    elif(base.switches[0].read() == 0 and base.switches[1].read() == 0):\n",
    "    # cap = cv2.VideoCapture(0)\n",
    "#size2 = (640,480)\n",
    "        flag=0\n",
    "        ret, frame = cap.read()\n",
    "        if (ret):      \n",
    "            frame = cv2.resize(frame,size1,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "            np_frame = frame\n",
    "            gray = cv2.cvtColor(np_frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade1.detectMultiScale(gray, 1.3, 5)\n",
    "            for (x,y,w,h) in faces:\n",
    "                cv2.rectangle(np_frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "            frame = cv2.resize(frame, (0, 0), fx=fx, fy=fy, interpolation=cv2.INTER_CUBIC)\n",
    "            outframe = hdmi_out.newframe()\n",
    "            outframe[0:480,0:640,:] = frame[0:480,0:640,:]\n",
    "            hdmi_out.writeframe(outframe)\n",
    "        else:\n",
    "            raise RuntimeError(\"Failed to read from camera.\")\n",
    "\n",
    "            \n",
    "            \n",
    "    elif(base.switches[0].read() == 1 and base.switches[1].read() == 1):\n",
    "        flag=0\n",
    "        ret, frame = cap.read()\n",
    "        if (ret): \n",
    "            frame = cv2.resize(frame,size1,interpolation=cv2.INTER_AREA)\n",
    "            predicted_img1 = predict(frame)\n",
    "            predicted_img1 = cv2.resize(predicted_img1, (0, 0), fx=fx, fy=fy, interpolation=cv2.INTER_CUBIC)\n",
    "        #plt.imshow(predicted_img1[:,:,[2,1,0]])\n",
    "        #plt.show()\n",
    "        #predicted_img1 = cv2.resize(predicted_img1,size1,interpolation=cv2.INTER_AREA)\n",
    "            outframe = hdmi_out.newframe()\n",
    "            outframe[0:480,0:640,:] = predicted_img1[0:480,0:640,:]\n",
    "            hdmi_out.writeframe(outframe)\n",
    "        #cv2.imshow(subjects[1], cv2.resize(predicted_img1, (640, 480)))\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            raise RuntimeError(\"Failed to read from camera.\")\n",
    "            \n",
    "    elif(base.switches[0].read() == 0 and base.switches[1].read() == 1):\n",
    "        flag=0\n",
    "        ret, frame = cap.read()\n",
    "        if (ret): \n",
    "            outframe = hdmi_out.newframe()\n",
    "        #cv2.Canny(frame, 100, 110, edges=outframe)\n",
    "            laplacian_frame = cv2.Laplacian(frame, cv2.CV_8U, dst=outframe)\n",
    "        #outframe[0:480,0:640,:] = frame[0:480,0:640,:]\n",
    "            hdmi_out.writeframe(outframe)\n",
    "        else:\n",
    "            raise RuntimeError(\"Failed to read from camera.\")\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "        break \n",
    "        \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
